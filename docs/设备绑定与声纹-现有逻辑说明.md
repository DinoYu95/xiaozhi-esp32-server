# 设备绑定与声纹 — xiaozhi-server 现有逻辑说明

本文档说明当前 xiaozhi-server 里**设备绑定**和**声纹识别**的代码逻辑与数据流，便于和产品化设计对照。

---

## 一、设备绑定（现有逻辑）

### 1. 入口：连接时拉「设备私有配置」

- 设备连上 xiaozhi-server 时带上 **device-id**（WebSocket header，即 MAC 地址等设备唯一标识）。
- 若配置了 **read_config_from_api = true**（智控台模式），会异步调用：
  ```text
  get_private_config_from_api(config, device_id, client_id)
    → get_agent_models(device_id, client_id, selected_module)
    → ManageApiClient POST /config/agent-models
    → body: { macAddress, clientId, selectedModule }
  ```
- 即：**按 device_id（macAddress）向 manager-api 拉取该设备的「智能体/模型配置」**。

### 2. manager-api 侧（ConfigServiceImpl.getAgentModels）

- **按 MAC 查设备**：`deviceService.getDeviceByMacAddress(macAddress)`。
- **设备不存在**：
  - 先查 Redis 是否有该设备待绑定的**绑定码**：`deviceService.geCodeByDeviceId(macAddress)`；
  - 若有绑定码 → 抛 **10042（OTA_DEVICE_NEED_BIND）**，msg 里带**绑定码**（6 位）；
  - 若无 → 抛 **10041（OTA_DEVICE_NOT_FOUND）**。
- **设备存在**：根据设备的 **agentId** 查智能体、模型配置、音色、**声纹**、prompt、记忆等，拼成一个大 Map 返回给 xiaozhi-server。

### 3. xiaozhi-server 侧对返回结果的处理

- **manage_api_client.py**：
  - 若 API 返回 **code == 10041** → 抛 **DeviceNotFoundException**；
  - 若 **code == 10042** → 抛 **DeviceBindException(result.get("msg"))**，这里 **msg 即绑定码**（或含绑定码的提示），Python 里赋给 **conn.bind_code**。
- **connection.py**：
  - 在 **\_initialize_private_config_async** 里：
    - 正常拿到配置 → **need_bind = False**，**bind_completed_event.set()**，并把 private_config 合并进 self.config（含 voiceprint、prompt、Memory 等）；
    - **DeviceNotFoundException** → **need_bind = True**，不设置 bind_code；
    - **DeviceBindException(e)** → **need_bind = True**，**self.bind_code = e.bind_code**（即 API 的 msg，6 位绑定码）。

### 4. 未绑定时的行为：播报绑定码

- **消息路由**（_route_message）：若 **need_bind == True**，不处理正常对话，而是调 **\_discard_message_with_bind_prompt**；
- **\_discard_message_with_bind_prompt **：每隔 **bind_prompt_interval**（如 60 秒）调一次 **check_bind_device(conn)**；
- **receiveAudioHandle.check_bind_device(conn)**：
  - 若 **conn.bind_code** 存在且为 6 位 → TTS 播报：「请登录控制面板，输入 XXXXXX，绑定设备」，并播报 6 位数字的语音；
  - 若无 bind_code → 播报「没有找到该设备的版本信息，请正确配置 OTA 地址…」。

### 5. 小结（绑定）

| 环节           | 现有逻辑 |
|----------------|----------|
| 谁拉配置       | xiaozhi-server 按 **device-id** 调 manager-api **POST /config/agent-models** |
| 谁判断未绑定   | manager-api：设备不存在且 Redis 无绑定码 → 10041；有绑定码 → 10042，msg=绑定码 |
| 谁存绑定码     | 业务上由设备/OTA 侧在 Redis 写入，manager-api 只读；xiaozhi 只从 API 拿 msg |
| 未绑定时表现   | need_bind=True，播报「输入 X 绑定设备」+ 6 位数字语音，不进入正常对话 |
| 绑定后         | 设备在智控台侧录入后，再次拉配置时能查到设备，返回完整 agent 配置（含声纹等） |

---

## 二、声纹识别（现有逻辑）

### 1. 声纹配置从哪来

- 同上：**设备私有配置**由 **get_agent_models** 返回。
- **ConfigServiceImpl** 里会按当前设备的 **agentId** 查该智能体下的声纹列表（**AgentVoicePrintEntity**），拼成：
  - **voiceprint.url**：声纹服务地址（来自系统参数，如 `Constant.SERVER_VOICE_PRINT`），URL 里可带 `key=xxx`；
  - **voiceprint.speakers**：List<String>，每项格式 **"id, 名称, 介绍"**，例如 `"speaker_id_1, 小明, 家里孩子"`；
  - **voiceprint.similarity_threshold**：相似度阈值，默认 0.4。
- 若未配置声纹 URL 或 speakers 为空，则不下发 voiceprint，xiaozhi 侧不启用声纹。

### 2. xiaozhi-server 里声纹的初始化

- **connection.py**：在 **\_initialize_private_config_async** 里若 **private_config.get("voiceprint")** 存在，会 **self.config["voiceprint"] = private_config["voiceprint"]**。
- 初始化组件后，在 **\_initialize_voiceprint()** 中：
  - 读 **self.config.get("voiceprint", {})**；
  - 若存在则 **VoiceprintProvider(voiceprint_config)**，并 **self.voiceprint_provider = voiceprint_provider**（若 enabled）。
- **VoiceprintProvider**（core/utils/voiceprint_provider.py）：
  - 从 config 取 **url**（可含 ?key=）、**speakers**、**similarity_threshold**；
  - 解析 URL 得到 **base_url** 和 **api_key**（query 里的 key）；
  - **speakers** 每项按 `"id,name,description"` 解析，得到 **speaker_map[speaker_id] = {name, description}**；
  - 健康检查：GET **base_url/voiceprint/health?key=xxx**，成功则 **enabled = True**；
  - **identify_speaker(audio_data, session_id)**：POST **base_url/voiceprint/identify**，form-data 里 **speaker_ids=id1,id2,...**、**file=音频 wav**，返回 **speaker_id** 和 **score**；若 score ≥ threshold 且在 speaker_map 里，则返回 **name**，否则返回「未知说话人」或 None。

### 3. 声纹在识别流程中的调用

- **ASR 基类**（core/providers/asr/base.py）在「语音段结束、做一次识别」时：
  - 若有 **conn.voiceprint_provider** 且本段有音频，则把 PCM 转成 WAV，**与 ASR 并发**调 **conn.voiceprint_provider.identify_speaker(wav_data, session_id)**；
  - 声纹返回 **speaker_name**（或「未知说话人」/None）；
  - 把 **speaker** 写入本段结果：若 ASR 结果是 dict 则 **raw_text["speaker"] = speaker_name**，否则用 **\_build_enhanced_text** 拼成 **{"speaker": speaker_name, "content": text}** 的 JSON 字符串；
  - 该字符串会通过 **startToChat(conn, enhanced_text)** 进入后续对话流程。

### 4. 说话人信息在对话中的使用

- **receiveAudioHandle.startToChat**：若 JSON 里有 **speaker** 和 **content**，则 **conn.current_speaker = speaker_name**（并记录 language 等）；
- **dialogue.get_llm_dialogue_with_memory**：若传了 **voiceprint_config**，会把 **speakers** 里解析出的「id, 名称, 介绍」拼成一段 **<speakers_info>...</speakers_info>** 注入到 system prompt，便于 LLM 知道当前有哪些说话人；
- **intentHandler** 等也会从解析结果里取 **parsed_data.get("speaker")** 赋给 **conn.current_speaker**。

### 5. 小结（声纹）

| 环节           | 现有逻辑 |
|----------------|----------|
| 配置来源       | manager-api 按设备 agentId 查声纹表，返回 voiceprint.url + speakers（"id, 名称, 介绍"）+ similarity_threshold |
| 初始化         | connection 合并 private_config 后，\_initialize_voiceprint() 用 config["voiceprint"] 建 VoiceprintProvider，健康检查通过则 enabled |
| 调用时机       | ASR 在「一段语音结束」时与识别并发调 identify_speaker，把 PCM 转 WAV 上传声纹服务 |
| 声纹接口约定   | 健康检查 GET /voiceprint/health?key=；识别 POST /voiceprint/identify，form: speaker_ids, file（wav） |
| 结果使用       | 识别结果里带 speaker 字段；conn.current_speaker 存当前说话人名称；get_llm_dialogue_with_memory 可把 speakers 信息注入 system prompt |

---

## 三、和产品化设计的关系

- **绑定**：现有逻辑已具备「设备未绑定时返回绑定码 + 设备播报绑定码」；产品化时只需保证智控台/App 侧完成「用户输入绑定码 → 设备与账号/家庭绑定」并写入设备表，下次拉配置即走「设备存在」分支，并带上该设备下的声纹、偏好等。
- **声纹**：现有逻辑已具备「按设备（agent）下发的 speakers 列表做识别、结果写入 current_speaker」；产品化时只需在管理端维护「设备/智能体下的孩子档案（含声纹 id + 名称）」，仍用当前 **speakers** 格式（id, 名称, 介绍），即可复用现有 VoiceprintProvider 与 ASR 联动；若要做「按孩子隔离记忆」，只需在后续逻辑里用 **current_speaker**（或由 speaker_id 映射的 child_id）作为 memory role_id / zhiban user_id。
