# 家长端与多模态智伴 — 整体设计草案（讨论用）

本文档基于你提的 4 点需求，从**现有架构**出发，列出**数据库设计**和**各模块改动点**，便于一起讨论定稿后再落代码。未做实现，仅作方案草案。

---

## 一、现有架构与数据简要

### 1.1 manager-api（当前）

| 用途 | 表/模块 | 说明 |
|------|----------|------|
| 后台用户 | **sys_user**、**sys_user_token** | 管理端账号、密码/Token 登录 |
| 智能体 | **ai_agent** | user_id 指向 sys_user，智控台创建的 agent |
| 设备 | **ai_device** | user_id、agent_id、mac_address；绑定码在 Redis，绑定后写库 |
| 声纹 | **ai_agent_voice_print** | agent_id、id(speaker_id)、source_name、introduce、audio_id；按 agent 维度，无「孩子/家长」概念 |
| 聊天记录 | **ai_agent_chat_history**、**ai_agent_chat_audio** | agent_id、session_id、mac_address、content、audio_id 等；无 child_id |

- 设备拉配置：**get_agent_models(mac)** → 按 mac 查 ai_device → 取 agent → 拼 voiceprint（getVoiceprintsByAgentId）、prompt 等。
- 无「家长」账号、无「孩子」实体、无设备与孩子的绑定、无孩子偏好表。

### 1.2 xiaozhi-server（当前）

- 连接带 **device-id**；从 manager-api 拉私有配置（含 voiceprint.speakers）。
- 声纹识别后得到 **current_speaker**（名称），未统一成 child_id；**memory role_id** 与 **zhiban user_id** 均为 **device_id**，未传 child/speaker_type。
- 调 zhiban 时：**session_id、user_id（未传）**，无多模态（无图片、环境描述等）。

### 1.3 zhiban-agent（当前理解）

- 接口：**/api/chat**、**/api/chat/stream**，入参 **text、session_id、user_id（可选）**。
- Memory 按 **user_id**（或 device_id）维度设计，无 device_id+child_id 区分，无 speaker_type，无多模态入参。

---

## 二、需求 1：manager-api 支持家长端（复用且不影响后台）

### 2.1 目标

- 复用现有 manager-api，增加**家长端**能力。
- 新增：家长用户、家长-孩子、家长-设备关系；**孩子 = 声纹 speaker（child_id 即 speaker_id）**；孩子偏好表；设备与「主人孩子」绑定。
- 家长端登录：**微信登录、手机号验证码登录**；与现有 **sys_user（后台）** 隔离，不影响原有后台逻辑。

### 2.2 数据库设计（新增表，不动现有核心表）

| 表名 | 用途 | 主要字段（示例） |
|------|------|------------------|
| **parent_user** | 家长端用户 | id, open_id(微信), union_id, phone, nickname, avatar_url, create_time, update_time；与 sys_user 分离 |
| **parent_user_token** | 家长端登录态 | id, parent_user_id, token, expire_time, channel(wechat/mini_program/app) |
| **parent_device_binding** | 家长-设备绑定 | id, parent_user_id, device_id(mac 或 ai_device.id), bind_time, 来源(扫码/绑定码) |
| **device_owner_child** | 设备-主人孩子（一设备一主孩） | id, device_id(mac 或关联 ai_device), child_id(speaker_id), bind_time |
| **child_profile** | 孩子档案（与声纹一对一） | id(child_id = 声纹 id), parent_user_id, nickname, gender, birth_date, preference_text(JSON 或 text), create_time |
| **child_preference** | 孩子偏好（可结构化） | id, child_id, key, value, update_time；或与 child_profile.preference_text 二选一 |

说明与待定：

- **child_id 与声纹**：child_id 直接复用 **ai_agent_voice_print.id**（即 speaker_id），便于与现有声纹列表一致；或新建 child 表再关联 voice_print_id，二选一需定。
- **设备标识**：parent_device_binding、device_owner_child 用 **mac_address** 还是 **ai_device.id** 需统一（建议 mac，与现有 get_agent_models(mac) 一致）。
- **ai_device 是否扩展**：保持现有 ai_device（后台绑定 agent）不变；家长绑定设备仅用 **parent_device_binding**，不写 ai_device 的 user_id，避免与后台账号混用。若业务上「家长绑定」与「设备绑 agent」要强一致，可再议。

### 2.3 接口与模块改动（manager-api）

| 类型 | 内容 |
|------|------|
| **鉴权** | 新增 **家长端鉴权**：Filter/Interceptor 识别 **Parent-Token** 或 **Authorization: Bearer &lt;parent_token&gt;**，校验 parent_user_token，注入 ParentUser 上下文；与现有 sys_user 的 Shiro/Token 完全分离，按 URL 前缀或 Header 区分（如 /parent-api/** 走家长鉴权）。 |
| **登录** | 新增 **/parent-api/auth/wechat**、**/parent-api/auth/phone/code**（发码）、**/parent-api/auth/phone/login**；登录成功写 parent_user_token，返回 token 给 App/小程序。 |
| **家长-设备-孩子** | 家长绑定设备：**POST /parent-api/device/bind**（绑定码）；解绑：**POST /parent-api/device/unbind**；设置设备主人孩子：**PUT /parent-api/device/{deviceId}/owner-child**（body: child_id）；查询我的设备列表、某设备下的孩子列表。 |
| **孩子与偏好** | 孩子列表（含声纹来源）：可查 ai_agent_voice_print（按 parent 关联的 device→agent 查）或独立 child 表；偏好：**GET/PUT /parent-api/child/{child_id}/preference**。 |
| **配置下发** | **get_agent_models** 若需带「主人孩子、偏好」：在现有返回上增加字段即可（见下节）；或新增 **/parent-api/device/config** 仅给家长端用，与 get_agent_models 二选一/合并逻辑。 |

不动的部分：sys_user、ai_agent、ai_device 的增删改查与现有权限、智控台流程保持不变；仅新增 parent_* 表与 /parent-api/* 接口。

---

## 三、需求 2：声纹→zhiban 传递 + memory(device_id+child_id) + 主人/访客与存储

### 3.1 目标

- 声纹识别到的「谁在说话」传给 zhiban-agent（**user_id = child_id**，可选 **speaker_type**）。
- zhiban-agent 的 memory 从「按 device_id」改为「按 **device_id + child_id**」。
- **一设备只绑定一个主人孩子**；主人孩子的对话**全量写入 memory**；**非主人**（其他小孩、家长、陌生人）按「是否重要」决定是否存 memory、是否落库（访客/关系表）。

### 3.2 数据库设计（与需求 1 衔接）

| 表/用途 | 说明 |
|---------|------|
| **device_owner_child** | 已在上节：一设备一主人，child_id = speaker_id。 |
| **device_speaker_relation**（可选） | 设备上「非主人」的说话人：device_id, speaker_id(声纹id或临时id), speaker_type(enum: parent/other_child/other_adult/guest), relation_label(好友/家人等), first_seen_time, last_seen_time；用于「访客/关系」是否要存 memory、是否要存声纹。 |
| **visitor_voiceprint**（可选） | 若希望把访客声纹也入库以便下次识别：speaker_id, device_id, source_name, speaker_type, created_from_session_id；与 ai_agent_voice_print 可区分（按 agent/device 或 type 区分）。 |

逻辑约定（待定）：

- **主人**：device_owner_child.child_id；该 child_id 的对话 → memory 必存，user_id = device_id + child_id（或约定格式）。
- **非主人**：识别到 speaker 不在「该设备主人」则视为访客；是否存 memory、是否写入 device_speaker_relation/visitor_voiceprint，可由规则或 LLM 判断「关系/是否重要」后决定（见下）。

### 3.3 主人/访客与「是否存储」规则（设计选项）

- **方案 A（简单）**：仅主人对话写 memory 和长期存储；非主人一律不写 memory、不落库。
- **方案 B（关系判断）**：非主人说话时，用**当前轮对话内容**（或结合历史）调用一次**轻量 LLM/规则**判断：是否「家人/好友」等重要关系；若是则写入 device_speaker_relation，并可选写入 visitor_voiceprint 和一次性的 memory 片段；若为「普通游客」则不写。
- **方案 C（全部落库，后处理）**：非主人对话先落「原始会话表」（带 speaker_id、device_id），后续离线/定时用 LLM 打标签（关系、是否重要），再决定是否同步到 memory 或展示给家长。

建议先定：**是否只存主人**（A）还是**要存部分访客**（B/C），再细化规则与表结构。

### 3.4 各端改动点

| 端 | 改动 |
|----|------|
| **manager-api** | get_agent_models 返回中增加：**owner_child_id**（该设备主人 child_id）、**child_preferences**（主人偏好）；可选返回 speakers 中每项的 **child_id/speaker_type**。 |
| **xiaozhi-server** | ① 计算 **current_child_id**（声纹对应 speaker_id，若与 owner_child_id 一致即主人）；② **role_id** = device_id + "_" + child_id（或约定格式）；③ 调 zhiban 时传 **user_id=role_id**，并新增 **speaker_type**（owner/parent/other_child/other_adult/guest）；④ 若采用 B/C，在识别到非主人时调「关系判断」或写 device_speaker_relation/visitor 表（需 manager-api 提供接口）。 |
| **zhiban-agent** | ① Memory 的 user_id 改为接收 **device_id+child_id**（或 role_id），按该维度分区存储；② 可选：接收 **speaker_type**，用于回复策略（见需求 4）；③ 若要做「访客 memory」：可对非 owner 的 user_id 使用不同存储策略（如只存短期、不参与长期召回）。 |

---

## 四、需求 3：多模态输入（图片、环境描述、主人语音）与 zhiban 结合

### 4.1 目标

- xiaozhi-server 接收：**主人音频**、**环境图**、**硬件给出的环境描述文本**、**主人说的话（文本）** 等。
- zhiban-agent 能结合这些多模态信息，设计成「能和小孩对话的智能体系统」。

### 4.2 数据流与接口形态（建议）

| 输入类型 | 来源 | 进入 xiaozhi 的方式 | 传给 zhiban 的方式 |
|----------|------|---------------------|---------------------|
| 主人语音 | 设备/App | 现有 WebSocket 音频流 → ASR → 文本 | 已有：text + session_id + user_id |
| 主人说话文本 | 设备/App | WebSocket JSON（如 type=text） | 同上 |
| 环境图片 | 设备 | 新：WebSocket binary 或 JSON(base64/url) 或 HTTP 上传 | 新：image_url 或 image_base64 数组 |
| 环境描述 | 设备/硬件 | 新：WebSocket JSON 或与图片同包 | 新：context.env_description 或 system 段补充 |

建议 zhiban-agent 的 chat 接口扩展为例如：

- **text**, **session_id**, **user_id**（必选/已有）
- **speaker_type**（可选，需求 4）
- **images**：可选，List&lt;url 或 base64&gt;
- **context**：可选，如 `{"env_description": "客厅，有沙发和玩具"}`

zhiban 内部：将 text + images + context 拼成多模态 prompt（或走 vision model），再生成回复。

### 4.3 各端改动点

| 端 | 改动 |
|----|------|
| **xiaozhi-server** | ① 消息路由：除 str(bytes) 外，支持新类型（如 **type=image**、**type=env_context**），或在新 WebSocket 消息里带 image_url/env_description；② 在调用 zhiban 前，将**本轮/本会话**的「环境描述、最近一张环境图」与用户文本一起组装；③ 若图片先上传到 manager-api/OSS，则只传 url 给 zhiban。 |
| **zhiban-agent** | ① **/api/chat**、**/api/chat/stream** 增加 **images[]**、**context**；② 内部：多模态模型或先将 image 转描述再与 text、env_description 拼进 prompt；③ Memory 若需存「环境摘要」，可增加 metadata 或单独 context 存储（可选）。 |

### 4.4 多模态下的 Memory 设计（含环境信息与交互感）

多模态（环境图、环境描述、对话）的本质是：**让智伴「看得见、记得住、接得上」**，用户才会觉得产品是「在和我一起经历」而不是「只会答话」。下面从「要什么体验 → 存什么 → 怎么存 → 怎么用」把多模态 memory 设计补全。

#### 4.4.1 目标体验：为什么这样设计能提升交互感

| 体验目标 | 用户感知 | 多模态 memory 的支撑 |
|----------|----------|------------------------|
| **看得见** | 「它知道我现在在干嘛、身边有什么」 | 当前轮/会话的**环境信息**（图或描述）参与当轮回复，而不是只靠文字。 |
| **记得住** | 「它记得上次我们在客厅搭乐高」「上次你说喜欢恐龙」 | **对话记忆**（已有）+ **情境记忆**（在哪儿、在做什么）能一起被召回，形成连续叙事。 |
| **接得上** | 「你旁边那本书我们上次读过」「现在在书房，要一起听故事吗」 | 检索时同时用到「当前环境」和「历史情境+对话」，回复时自然引用空间与过往。 |

因此，多模态 memory 不仅要存「说了什么」，还要存「在什么情境下说的」「当前/当时的环境长什么样」，并在回复时**同时注入当前环境 + 召回的情境与对话**，才能让交互感明显提升。

#### 4.4.2 多模态记忆要存什么（对话 vs 环境/情境）

- **对话记忆（已有）**  
  - 内容：用户与助手的多轮对话、摘要、关键事实（名字、喜好等）。  
  - 维度：按 **user_id**（device_id+child_id）隔离。  
  - 不变：继续用现有短期摘要 + 长期 Mem0（或等价）即可。

- **环境/情境记忆（新增）**  
  - **当前会话环境**：本轮或本会话的「环境描述 + 可选图片描述」，用于当轮回复的「看得见」。  
  - **可回忆的情境**：值得长期保留的「在哪儿、在做什么、和什么相关」的摘要，用于跨会话的「记得住、接得上」。

建议的**情境记忆粒度**（可先选子集落地）：

- **会话级快照**：每次会话开始或设备上报新环境时，形成一条「时间 + 地点/场景 + 简短描述（来自硬件或 vision）」。
- **关键情境**：与对话强绑定——例如「在客厅玩积木时问了恐龙问题」：在写对话记忆时，把**当前环境摘要**作为该条记忆的 metadata 或同一段内容的一部分一起存，这样召回对话时自然带出情境。

这样既避免「只存对话、不知道当时在哪儿」，也避免「环境信息只当轮用、下次用不上」。

#### 4.4.3 存储形态：与现有 Memory 的关系

两种思路（可二选一或组合）：

- **方案 A：统一记忆体，用类型/metadata 区分**  
  - 在现有 Mem0（或同一长期记忆）里，除对话外增加一类「情境」记忆。  
  - 例如：写入时增加 **metadata**（如 `type: "situation"` / `type: "environment"`），内容为自然语言摘要：「2025-02-13 下午，客厅，孩子在玩积木，旁边有绘本和沙发。」  
  - 检索时：  
    - 用**当前 query** 做语义检索，同时拉取对话类 + 情境类记忆；或  
    - 对话用 query 检索，情境用「最近 N 条」或「与 query 相关」单独检索再合并。  
  - 优点：一套存储、统一 user_id，实现简单。  
  - 缺点：情境和对话混在一起，若检索未做类型过滤，需要 prompt 里区分使用方式。

- **方案 B：分层存储**  
  - **对话记忆**：保持现有短期 + 长期（按 user_id）。  
  - **情境记忆**：单独表或单独 key/namespace（如 `user_id` + `type=situation`），每条：user_id, session_id（可选）, content（环境+场景摘要）, source（env_description / image_caption）, created_at。  
  - 回复时：先查对话记忆，再取「最近情境」或「与 query 相关的情境」合并进 prompt。  
  - 优点：职责清晰，便于只刷新「当前环境」、只召回「历史情境」。  
  - 缺点：多一层存储与组装逻辑。

**推荐**：先采用 **方案 A**（在现有 memory 中增加带 type 的情境条），便于快速验证「环境参与回忆」的交互效果；若后续需要更细的 TTL、按场景过滤等，再拆成方案 B。

#### 4.4.4 何时写入：环境 vs 对话

- **当前会话环境（不当长期记忆写，只参与当轮）**  
  - 每次设备上报 **env_description** 或 **image** 时，在当轮请求里直接带给 zhiban（如 `context.env_description`、`images`），**不强制写入长期 memory**，只用于当轮「看得见」。  
  - 若希望「本会话内后续几轮也能用」，可在 xiaozhi 或 zhiban 的**会话级上下文**里保留「最近一条环境描述」（会话内缓存即可）。

- **何时写「可回忆的情境」到长期 memory**  
  - **时机 1**：会话开始时，若本轮有 env_description 或生成了 image_caption，写一条情境记忆（如「某日某时，客厅，…」），user_id 同上。  
  - **时机 2**：在**写对话记忆时**（例如已有「回复后写 memory」的逻辑），把**当前环境摘要**一并写入同一条或关联一条情境记忆，这样「说了什么」和「在什么情境下」绑定在一起，便于后续一起被召回。  
  - 避免：每轮都写重复的环境，容易造成噪音；可约定「环境变化时写」或「每会话至多 1 条 + 与关键对话绑定的一条」。

- **对话记忆**  
  - 保持现有逻辑：在**有完整回复后**写对话/摘要，不变；若采用「绑定情境」，则在写对话记忆时附带当前 env 摘要（见上）。

#### 4.4.5 检索与使用：回复时如何注入，让交互感拉满

回复一轮请求时，建议按下面顺序组装上下文（在 zhiban 或 xiaozhi 侧均可，视谁负责 memory 而定）：

1. **当前环境（必选）**  
   - 本轮请求里的 `context.env_description` 和/或 `images`（或 image 的 caption）。  
   - 直接放进 system 或 user 段，例如：「[当前环境] 客厅，有沙发和乐高，孩子正在玩积木。」  
   - 这样模型能自然说出「我看到你在玩积木哦」「你旁边的绘本要不要一起看」等，**即时有交互感**。

2. **召回的记忆（对话 + 情境）**  
   - 用 **user_id + 当前 query** 做语义检索（若用方案 A，可对 type 做过滤或混合召回）。  
   - 将召回结果格式化为「历史记忆：…」注入 system 或 context。  
   - 若采用「对话+情境绑定」的写法，召回的一条里可能同时包含「当时说了什么」和「当时在哪儿」，模型就能接「上次你在客厅说喜欢恐龙」这类连续叙事。

3. **孩子偏好（可选）**  
   - 从配置或 child_profile 来的偏好，与多模态 memory 并列注入，进一步个性化。

4. **当轮用户输入**  
   - 用户本轮文本（+ 若有 image，可再强调「用户发来一张图：…」）。

这样，**单轮回复 = 当前环境 + 历史情境与对话 + 偏好 + 当轮输入**，产品会明显更「有记忆、有场景、接得住」。

#### 4.4.6 短期 vs 长期：当前会话环境 vs 跨会话回忆

- **短期（当前会话）**  
  - 「当前环境」：仅在本会话内保留最近一条（或最近几条）env_description / image_caption，用于本会话多轮对话的连贯性，**不必都写进长期 memory**。  
  - 实现：在 xiaozhi 的 session 或 zhiban 的 conversation 里维护一个 `last_env` 即可。

- **长期（跨会话）**  
  - 只把「值得回忆的情境」写进长期 memory（见 4.4.4），避免每轮都写重复环境。  
  - 检索时与对话记忆一起按 user_id 召回，用于「上次在书房」「上次玩积木时你说…」等。

#### 4.4.7 小结与待定

- **多模态 memory 设计**：在现有「对话记忆」基础上，增加**情境/环境类记忆**（统一 store + type/metadata，或分层 store）；**当前环境**每轮直接入 prompt，「可回忆的情境」按会话/关键对话写入并参与检索。  
- **交互感**：通过「当前环境 + 召回的情境与对话 + 偏好 + 当轮输入」一起注入，让智伴能「看得见、记得住、接得上」。  
- **待定**：环境是「每会话 1 条」还是「仅与关键对话绑定写」；情境记忆的 TTL 或条数上限；是否用 vision 对图片生成 caption 再存（若存图描述的话）。

---

## 五、需求 4：按说话人类型（家长/别的小孩/别的大人）差异化响应

### 5.1 目标

- 智伴主要面向**小孩**，但对**家长、别的小孩、别的大人**给出不同风格/内容的回复（如对家长更简洁、对别的小孩更活泼、对陌生人更收敛）。

### 5.2 设计要点

- **speaker_type** 在 xiaozhi 侧即可区分：主人孩子 / 家长 / 其他小孩 / 其他大人 / 访客（若声纹未识别可默认 guest）。
- 家长识别：可在 **child_profile** 或 device 上配置「家长声纹 speaker_id」；或由设备/业务约定「某 speaker_id 为家长」；识别到该 speaker 时传 **speaker_type=parent**。
- zhiban-agent：接收 **speaker_type**，在 system prompt 或路由逻辑中约定「若 speaker_type=parent 则…，other_child 则…，other_adult 则…」，从而生成不同风格的回复。

### 5.3 各端改动点

| 端 | 改动 |
|----|------|
| **manager-api** | 若需在配置里区分「家长声纹」：可在 get_agent_models 的 speakers 中为每项增加 **speaker_type**（owner/parent/child），或单独返回 **parent_speaker_ids**。 |
| **xiaozhi-server** | 根据 current_speaker 与配置的 owner_child_id、parent_speaker_ids 等，计算 **speaker_type**，调 zhiban 时传入。 |
| **zhiban-agent** | **/api/chat** 增加 **speaker_type**；内部 system prompt 或 router 按 speaker_type 选择不同 prompt/策略。 |

---

## 六、Agent 提示词 Skill 化（类 Claude 项目管理）

### 6.1 现状与问题

- **当前做法**：每个 agent 在库里有**一个** `system_prompt` 大字段；智控台/模板里再叠一层固定结构（如 xiaozhi 的 `agent-base-prompt.txt`：身份、情绪、沟通风格、长度约束、说话人、工具、context、memory 等）。  
- **问题**：  
  - 不同 agent 只能「各写一整段提示词」，**无法复用**「对家长回复」「儿童语气」「多模态环境」等公共片段。  
  - 改一处逻辑（如「对家长要简洁」）要改多个 agent 的 prompt，**难维护、难 A/B**。  
  - 和「按 speaker_type 差异化」「多模态」等扩展挤在同一段里，**职责不清**。

### 6.2 目标：像 Claude 一样用 Skill 管理

类似 Claude 的 **Project 说明 / 技能文件** 思路：把提示词拆成**可复用的 Skill 块**，每个 agent **引用一组 Skill + 可选顺序与覆盖**，运行时再**组装**成最终 system prompt。这样：

- **更好管理**：一个 Skill 一处维护，多个 agent 共用。  
- **职责清晰**：例如「儿童语气」「对家长回复」「环境理解」「工具调用」各一个 Skill。  
- **易扩展**：新增 speaker_type、多模态时，加新 Skill 或改现有 Skill，不必改每个 agent 的大段文本。  
- **易迭代**：可对单个 Skill 做版本/灰度，而不动整份 prompt。

### 6.3 设计思路（可落 manager-api + 可选 zhiban-agent）

**（1）Skill 定义**

- **表或配置**：每条 Skill 有唯一 id、名称、**内容**（一段 prompt 文本）、**分类**（如 identity / emotion / communication / speaker_response / tool / context / memory）、排序用 sort。  
- **内容**：可支持简单占位符（如 `{{assistant_name}}`、`{{speaker_type}}`），组装时由上层替换。

**（2）Agent 与 Skill 的绑定**

- **方式 A**：agent 表保留 `system_prompt` 作为「自定义扩展」或**兜底**，同时增加「Agent 使用的 Skill 列表」：例如表 `ai_agent_skill`（agent_id, skill_id, sort, optional_override 文本），表示该 agent 使用哪些 Skill、顺序如何、是否覆盖某 Skill 的默认内容。  
- **方式 B**：agent 不再存整段 system_prompt，只存「Skill 列表 + 顺序 + 可选覆盖」；最终 prompt 完全由 Skill 组装而成。

**（3）运行时组装**

- **get_agent_models**（或等价接口）返回时：  
  - 要么返回**已组装好的** `prompt`（向后兼容），  
  - 要么返回 **skills** 数组（每项含 id、name、content、sort），由 xiaozhi 或 zhiban-agent 按顺序拼接成 system prompt；若 agent 有 override，则用 override 替换对应 skill 的 content。  
- 与现有 **模板** 的关系：  
  - 可将现有 `agent-base-prompt.txt` 拆成多个 Skill（如 `<emotion>` → skill「情绪与表情」、`<communication_style>` → skill「沟通风格」），  
  - 模板中只保留「壳」（如占位 `{{skill_blocks}}`），由「Skill 块按序拼接」填充。

**（4）与 speaker_type、多模态的衔接**

- 「按说话人类型差异化」：可做成独立 Skill，例如 **speaker_response**：内容里写「若 speaker_type=parent 则…，other_child 则…」，或由运行时根据当前 speaker_type 注入不同片段。  
- 多模态、环境：可做成 **context_skill**，内容为「当前环境：{{env_description}}；图片描述：…」，由上游在组装时填入当轮数据。  
- 这样「不同 agent 往里面写提示词」变成「不同 agent 选不同 Skill 组合 + 少量覆盖」，结构清晰、易维护。

### 6.4 落地位置建议

| 位置 | 做法 |
|------|------|
| **manager-api** | 新增 **ai_skill** 表（id, name, content, category, sort）、**ai_agent_skill** 表（agent_id, skill_id, sort, content_override）；get_agent_models 时按 agent 查绑定的 skills，按 sort 排序，组装成 prompt 或返回 skills 列表；智控台增加「Skill 管理」与「Agent 绑定 Skill」配置。 |
| **xiaozhi-server** | 若 API 返回已组装 prompt，则无需改；若返回 skills 数组，则增加「按 skills 拼接 + 占位符替换」的逻辑，再交给现有 prompt_manager / 对话。 |
| **zhiban-agent** | 若 zhiban-agent 自管 system prompt，可在其侧也引入「Skill 文件」：例如按 skill_id 或 name 的文本/配置文件，agent 配置中指定「使用哪些 skill 文件、顺序」，启动或请求时加载并拼接；与 manager-api 的 skill 可共用一个 id/name 约定，便于两端一致。 |

### 6.5 小结

- **可以**也**建议**用「Skill 化」方式管理 agent 提示词：**定义 Skill → Agent 绑定 Skill + 顺序/覆盖 → 运行时组装**，实现类似 Claude 的清晰、可复用、易扩展。  
- 与「家长端、多模态、speaker_type」兼容：新能力做成新 Skill 或扩展现有 Skill，不破坏现有 agent 配置。  
- 具体先做 **manager-api 侧 Skill 表 + 绑定 + 组装下发**，再视需要让 xiaozhi/zhiban-agent 支持「按 skills 数组拼接」或继续使用组装好的 prompt，均可。

---

## 七、数据库变更汇总（仅新增，供讨论）

| 表名 | 说明 |
|------|------|
| parent_user | 家长端用户（微信/手机） |
| parent_user_token | 家长端登录 Token |
| parent_device_binding | 家长-设备绑定 |
| device_owner_child | 设备-主人孩子（一设备一孩） |
| child_profile | 孩子档案（child_id 可= speaker_id，含偏好摘要） |
| child_preference | 孩子偏好（可选，或合并入 child_profile） |
| device_speaker_relation | 设备上非主人说话人及关系（可选） |
| visitor_voiceprint | 访客声纹（可选） |
| ai_skill | Agent 提示词 Skill 定义（可选，见第六节） |
| ai_agent_skill | Agent 与 Skill 绑定及顺序、覆盖（可选） |

**现有表**：ai_device、ai_agent、ai_agent_voice_print、ai_agent_chat_*、sys_user 等**不删不改字段**，仅通过新表与现有表关联（如 device 用 mac，child 用 speaker_id）。

---

## 八、代码/模块改动清单（按端）

### 8.1 manager-api

- 新增模块：**parent**（parent_user、登录、绑定、孩子与偏好）。
- 新增鉴权：ParentToken 过滤器，/parent-api/** 走家长 Token。
- 登录：微信、手机验证码（对接微信 API、短信服务）。
- 设备/孩子/偏好：parent_device_binding、device_owner_child、child_profile 的 CRUD；get_agent_models 扩展返回 owner_child_id、child_preferences、speaker_type（可选）。
- 若做访客存储：提供 device_speaker_relation、visitor_voiceprint 的写接口（或由 xiaozhi 直写 DB，不推荐）。
- **Skill 化（可选/推荐）**：新增 ai_skill、ai_agent_skill 表；智控台「Skill 管理」+「Agent 绑定 Skill」；get_agent_models 支持按 Skill 组装 prompt 或返回 skills 列表。

### 8.2 xiaozhi-server

- connection：**role_id** = f(device_id, current_child_id)；调 LLM 时传 **user_id**、**speaker_type**（若 ZhibanAgent）。
- voiceprint：在 conn 上落 **current_speaker_id**（与配置 speakers 对应），并解析 **owner_child_id**、**speaker_type**。
- 多模态：新消息类型解析；组装 images、context 调用 zhiban。
- 可选：非主人时的关系判断调用、上报 device_speaker_relation（若接口在 manager-api）。

### 8.3 zhiban-agent

- **/api/chat**、**/api/chat/stream**：入参增加 **user_id**（必填，格式 device_id+child_id 或 role_id）、**speaker_type**、**images**、**context**。
- Memory：按 **user_id** 分区（已是 device+child 维度）；区分 owner/visitor 的存储策略（可选）。
- 多模态：接收 images、context，拼进 prompt 或走 vision。
- 回复策略：按 speaker_type 选择不同 system prompt 或分支逻辑。
- **Skill 化（可选）**：若采用 Skill 管理，可支持按「skills 列表」加载并拼接 system prompt，与 manager-api 的 skill id/name 约定一致。

---

## 九、手机 App / 微信小程序：设备联网与绑定体验设计

本节从**用户买设备后第一次使用**的角度，设计「设备联网 + 在 App/小程序里完成绑定」的**完整流程与最佳体验**，并说明设备端、App/小程序端、服务端的职责与接口约定。

> **绑定流程与改造清单（含流程图）**：若需弄清「绑定码从哪来、二维码扫了调什么接口、和 xiaozhi 如何关联」以及「现有 vs 新增/修改」的逐项对照，请见 **[设备绑定流程与改造说明-含图.md](./设备绑定流程与改造说明-含图.md)**。

### 9.1 目标用户与目标体验

- **用户**：家长（已注册/登录 App 或微信小程序）。
- **目标**：买回设备 → 通电 → 联网（若需要）→ 打开 App/小程序 → 添加设备 → **最少步骤、最少困惑**地完成绑定，设备能正常对话、受该家长账号管理。
- **最佳体验原则**：步骤少、提示清晰、出错可恢复、设备侧与 App 侧状态一致（绑定成功即设备马上能用的感觉）。

### 9.2 整体流程概览（用户视角）

```
用户买设备
    → 通电开机
    → 设备首次联网（见 9.3：WiFi 配网或直连）
    → 设备自动上报服务器，获得 6 位绑定码并播报/展示
    → 用户打开「手机 App」或「微信小程序」
    → 登录（微信一键 / 手机验证码）
    → 进入「添加设备」
    → 输入 6 位绑定码（或扫设备上的二维码，见 9.5）
    → 确认绑定
    → 绑定成功：App 显示「已添加」，设备播报「绑定成功」并开始正常服务
```

下面分「设备侧」「App/小程序侧」「服务端」拆解，并给出推荐方案与可选增强。

### 9.3 设备侧：首次联网与绑定码

**（1）设备如何联网**

- **方案 A（常见）**：设备首次开机进入**配网模式**（如设备热点 / 声波配网 / 蓝牙辅助配网），用户用手机连设备热点或在同一 WiFi 下完成配网，设备获得家庭 WiFi，再连互联网。
- **方案 B**：设备支持**有线/4G 等**，插网线或插卡即联网，无需用户配网。
- **建议**：在文档与 App 内明确「首次使用请按说明书完成联网」，并在「添加设备」页提供**说明书/配网引导**入口（图文或短视频），减少「设备离线导致拿不到绑定码」的困惑。

**（2）设备上报与绑定码的生成（与现有逻辑一致）**

- 设备联网后，按固件逻辑调用 **manager-api 的设备上报接口**（如 OTA/checkDeviceActive 或现有 report 接口），上报 **mac_address**（即 device-id）、板型、版本等。
- 服务端：若该 device-id **在 Redis 中尚无待绑定数据**，则**生成 6 位数字绑定码**，写入 Redis（`ota:activation:code:{code} → deviceId`，`ota:activation:data:{deviceId} → {activation_code, mac_address, ...}`），并返回该 code 给设备（若接口有返回）；若已有则返回已有 code。
- **设备需要做的**：在收到或轮询到「当前绑定码」后，以**语音 + 可选屏幕/二维码**的方式呈现给用户（见下），并进入「等待绑定」状态（未绑定前不提供正常对话，仅播报绑定提示）。

**（3）绑定码的呈现方式（最佳体验建议）**

| 方式 | 说明 | 推荐 |
|------|------|------|
| **语音播报** | 设备定时播报「请打开 App，输入 XXXXXX 绑定设备」（与现有 xiaozhi 逻辑一致） | ✅ 必选，已有 |
| **屏幕显示** | 若设备有屏，常显 6 位数字 + 简短说明「请在 App 中输入」 | ✅ 强烈建议，减少听错、抄错 |
| **二维码** | 设备屏或机身贴纸展示二维码，内容为 `{"code":"123456"}` 或带服务端域名 + code 的短链 | ✅ 推荐，小程序/App 扫一扫即可填码，体验最佳 |
| **二维码 + 数字** | 同时显示 6 位数字与二维码，兼顾「无摄像头/不想扫码」的用户 | ✅ 最佳 |

**（4）设备在「未绑定」时的行为（与现有一致）**

- 设备以 **device-id（mac）** 连 xiaozhi-server；xiaozhi 拉取配置时若该设备未在 ai_device（或未在家长绑定关系内，视业务定），则 **need_bind = True**，设备端只收到「绑定提示」TTS，不进入正常对话，避免误用。

### 9.4 App / 小程序侧：添加设备流程

**（1）入口与前置条件**

- 入口：首页或「我的」中的 **「添加设备」/「绑定新设备」**。
- 前置：用户已登录（微信或手机号），持有 **parent_user_id** 与有效 Token。

**（2）主流程（推荐：先引导再看码）**

1. **步骤 1：引导页（可选但推荐）**  
   - 文案示例：「请确保设备已通电并联网，设备会语音播报 6 位绑定码，或在屏幕上显示。」  
   - 提供「设备如何联网」说明入口；若支持扫码绑定，写「您也可以扫描设备屏幕上的二维码快速绑定」。  
   - 按钮：「已准备好，去输入绑定码」/「扫描设备二维码」。

2. **步骤 2a：输入绑定码**  
   - 单个输入框：**6 位数字**，可自动格式化（如 123-456 或每格一位）。  
   - 输入完成后「下一步」或直接「绑定」；校验格式（6 位数字）后再请求服务端。  
   - 若设备支持二维码：提供「扫一扫」入口，扫码后解析出 code，自动填入并进入确认。

3. **步骤 2b：扫码绑定（若支持）**  
   - 调起相机/小程序扫码，解析二维码内容（JSON 的 code 或短链重定向到带 code 的 H5）；  
   - 解析得到 code 后，与「输入绑定码」走同一套绑定请求与结果页。

4. **步骤 3：确认绑定**  
   - 可展示「即将绑定设备，绑定后可在「我的设备」中管理」，确认后发 **POST /parent-api/device/bind**，body：`{ "code": "123456" }`（见 9.6）。

5. **步骤 4：结果页**  
   - **成功**：提示「绑定成功」，可跳转「我的设备」或「去设置孩子/主人」；若与设备有长连/推送，可提示「设备将播报绑定成功」增强体感。  
   - **失败**：根据服务端错误码给出明确文案（见 9.7），并提供「重试」或「重新输入绑定码」。

**（3）体验细节建议**

- **自动聚焦**：进入输入页即聚焦到绑定码输入框，支持粘贴 6 位数字。  
- **防重复提交**：点击绑定后按钮 loading，禁止二次点击直至返回。  
- **弱网/超时**：友好提示「网络不稳定，请重试」并保留已输入 code。  
- **绑定码有效期**：若服务端对 Redis 的 code 设 TTL（如 10 分钟），在引导页或输入页提示「绑定码有效期为 10 分钟，过期请在设备上重新获取」。

### 9.5 二维码内容与生成（设备端 / 服务端）

- **内容形态一（推荐）**：JSON 字符串，例如 `{"t":"device_bind","code":"123456"}`，小程序/App 扫码后解析 `code` 用于绑定。  
- **内容形态二**：短链，例如 `https://your-domain.com/bind?c=123456`，扫码后打开 H5 或 App 调起页，由 H5/App 解析 `c` 并调起小程序或原生「添加设备」页并带入 code。  
- **生成位置**：  
  - 若设备有屏：设备在收到绑定码后，本地生成二维码图片并显示（可调服务端「生成绑定二维码」接口拿 content，或设备本地用 code 按约定格式生成）；  
  - 若设备无屏：可在机身贴纸印「首次绑定请打开 App 输入 6 位码」，不强制二维码。  
- **安全**：二维码仅携带 code，不携带敏感信息；code 本身有时效且一次性使用（绑定成功后 Redis 删除），风险可控。

### 9.6 服务端：家长端绑定接口与逻辑

**（1）接口**

- **POST /parent-api/device/bind**  
  - 鉴权：Parent-Token（家长端登录态）。  
  - Body：`{ "code": "123456" }`（6 位数字字符串）。  
  - 成功：200，body 可含 `{ "deviceId": "xx", "message": "绑定成功" }`。  
  - 失败：4xx/5xx，错误码见 9.7。

**（2）后端逻辑（与现有设备激活对齐）**

- 用 **code** 查 Redis：`ota:activation:code:{code}` → 得到 **deviceId**；再用 `ota:activation:data:{deviceId}` 得到设备信息（mac_address、activation_code 等）。  
- 校验：  
  - 若 code 不存在或已过期 → 返回「绑定码无效或已过期」。  
  - 若 cache 中 `activation_code` 与入参 code 不一致 → 返回「绑定码错误」。  
  - 若该 deviceId **已在 ai_device 表中**且业务上不允许重复绑定（或已绑其他家长）→ 返回「该设备已被绑定」。  
- 绑定动作（与家长端设计一致）：  
  - **创建或更新 ai_device**：若当前业务是「家长绑定即创建设备」则插入 ai_device（device_id=deviceId, agent_id=默认或家长所选, user_id 可留空或系统账号）；若业务是「设备须先由智控台绑定 agent，家长只做关联」则仅确保 ai_device 存在且可被该家长使用。  
  - **创建 parent_device_binding**：parent_user_id = 当前家长，device_id = deviceId（或 mac），bind_time = now。  
  - **清理 Redis**：删除 `ota:activation:code:{code}` 与 `ota:activation:data:{deviceId}`，避免重复使用。  
- 可选：若设备与 xiaozhi 有长连/推送，可发「绑定成功」指令给设备，触发设备播报「绑定成功」。

**（3）与现有智控台绑定的关系**

- **方案 A**：设备必须先由**智控台/后台**绑定到某 agent（ai_device 已存在），家长端仅做「家长-设备关联」（parent_device_binding）；设备拉配置仍按 ai_device.agent_id 等下发，家长端只获得「可见、可管理该设备」的权限。  
- **方案 B**：家长端绑定时可**选择默认智能体/模板**，若 ai_device 不存在则创建一条（agent_id=默认），并写入 parent_device_binding。  
- 具体选 A 还是 B 由「设备与 agent 」（见待讨论项 2）定；接口设计上兼容两种：绑定接口只负责「code → deviceId → parent_device_binding + 必要时 ai_device」。

### 9.7 错误码与用户提示

| 场景 | 建议错误码/类型 | App/小程序提示文案 |
|------|-----------------|---------------------|
| code 为空或格式错误 | 400 | 请输入 6 位数字绑定码 |
| code 在 Redis 不存在或过期 | 404 或 400 | 绑定码无效或已过期，请确认设备已联网并在设备上重新获取绑定码 |
| code 与 Redis 中不一致 | 400 | 绑定码错误，请核对后重试 |
| 设备已被其他账号绑定 | 409 | 该设备已被绑定，如需解绑请联系管理员或使用原账号解绑 |
| 设备已与本账号绑定 | 200 或 409 | 该设备已在您的设备列表中（可视为成功或提示已存在） |
| 网络/服务异常 | 5xx | 网络不稳定，请稍后重试 |

### 9.8 绑定成功后的设备端表现

- **xiaozhi-server**：下次该设备（device-id）建连并拉取配置时，因 ai_device 已存在（且家长绑定关系已建立，若 get_agent_models 会校验家长侧），返回正常配置，**need_bind = False**。  
- **设备**：收到正常配置后即可进入正常对话；若支持服务端推送/长连，可收到「绑定成功」事件后本地播报「绑定成功，我可以陪你聊天啦」之类，提升体感。

### 9.9 小结与待定

- **最佳体验**：设备联网 → 上报获码 → **语音 + 屏幕数字 + 二维码** 多通道呈现绑定码 → 用户 App/小程序 **登录 → 添加设备 → 输入码或扫码 → 确认 → 成功**；绑定成功后设备即刻可用，并在设备侧有「绑定成功」反馈。  
- **服务端**：家长端 **POST /parent-api/device/bind**，复用现有 Redis 绑定码体系，写 parent_device_binding，并按业务选择是否创建/更新 ai_device。  
- **待定**：设备与 agent 的创建时机（先智控台还是家长绑定即创建）；绑定码 Redis TTL；是否做「设备推送绑定成功」及实现方式（MQTT/长连等）。

---

## 十、待讨论与定稿项

1. **child_id 是否直接= ai_agent_voice_print.id**，还是独立 child 表再关联 voice_print_id。
2. **设备与 agent**：家长绑设备后，该设备是否必须已在 ai_device 中并绑好 agent（即先有智控台配置），还是家长端可独立「创建设备+选模板」。
3. **主人/访客存储策略**：仅主人（方案 A）还是部分访客（B/C）；若 B/C，关系判断的时机（实时 LLM vs 规则 vs 后处理）。
4. **多模态**：环境图是每轮带一张还是会话级；zhiban 是否接 vision 模型还是「图→描述」在 xiaozhi 完成再传文本。
5. **家长声纹**：是否在库中显式标记「家长」（如 parent_speaker_ids），还是仅通过 speaker_type 在 xiaozhi 里写死规则。
6. **多模态 Memory**：情境记忆采用「统一 store + type」还是「分层 store」；环境写入长期记忆的时机（每会话 1 条 vs 仅与关键对话绑定）；情境记忆的 TTL/条数上限；图片是否先做 vision caption 再存文本。
7. **Skill 化**：是否采纳「Skill 表 + Agent 绑定」；先只做 manager-api 组装下发，还是 xiaozhi/zhiban-agent 也支持按 skills 数组拼接；现有 agent-base-prompt.txt 如何拆成首批 Skill。
8. **设备绑定体验**：设备与 agent 创建时机（智控台先绑 vs 家长绑定时选默认 agent）；绑定码 Redis TTL；设备是否支持「绑定成功」推送/播报及实现方式（MQTT/长连）；二维码格式与生成位置（设备本地 vs 服务端接口）。

**小程序/App 表结构与接口清单**：针对家长端与设备绑定的**表结构**、**/parent-api 接口列表**、**登录/绑定等流程**与**请求响应示例**，已整理为 **[家长端与设备绑定-表结构与API接口文档.md](./家长端与设备绑定-表结构与API接口文档.md)**，便于与前端/产品对齐；其中明确标注了**新增**与**现有且需修改**的项。

以上为草案；可按条讨论修改，定稿后再拆任务落代码。
